{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.2. Differential transcription factor binding site analysis by MACS2\n",
    "\n",
    "Please familiarize yourselves with MACS2 using lecture 7 slides and manuals here:\n",
    "\n",
    "* <https://github.com/taoliu/MACS> \n",
    "* <https://github.com/taoliu/MACS/wiki>\n",
    "* <https://github.com/taoliu/MACS/wiki/Advanced\\%3A-Call-peaks-using-MACS2-subcommands>\n",
    "* <https://github.com/taoliu/MACS/wiki/Call-differential-binding-events>\n",
    "\n",
    "\n",
    "For more detailed information about MACS, see: <https://genomebiology.biomedcentral.com/articles/10.1186/gb-2008-9-9-r137>\n",
    "\n",
    "Here you can find information about the different data formats used in this project: <https://genome.ucsc.edu/FAQ/FAQformat.html#ENCODE>\n",
    "\n",
    "**Fill in parts where you see XXX.**\n",
    "\n",
    "### To get help how to run macs2 and info about the options use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#macs2 help\n",
    "macs2 -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help for specific subcommands\n",
    "macs2 predictd -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Estimation of the fragment length (1 point)\n",
    "Estimate the fragment length of the NR3C1 ChIP-seq reads at both time points 0h and 1h. Use ```macs2 predict``` subcommand. Do not estimate the fragment length for the ChIP-seq Control reads. In Step2, the fragment lengths are used to extend the ChIP-seq reads in 5' to 3' direction, use the same extension (estimated fragment length) for the ChIP-seq samples from both time points. Use, for example, the average fragment length of the two values. \n",
    "\n",
    "To interpret the peak model and cross-correlation plots, here might be some useful material \\\\ \\url{https://bioinformatics-core-shared-training.github.io/cruk-summer-school-2018/ChIP/Practicals/Practical3_peakcalling_SS.html} (especially section 1.1) which might help with the interpretation. You might also find helpful the article by \\cite{Ramachandran2013} <https://academic.oup.com/bioinformatics/article/29/4/444/200320> , which discusses the origin of the phantom peaks. Remember to add them to your references list and cite them properly, if you use these information resources.\n",
    "\n",
    "### Define bash variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dexamethasone_1hour_Control.bam      noTreatment_0hour_Control.bam\n",
      "dexamethasone_1hour_Control.bam.bai  noTreatment_0hour_Control.bam.bai\n",
      "dexamethasone_1hour_NR3C1.bam        noTreatment_0hour_NR3C1.bam\n",
      "dexamethasone_1hour_NR3C1.bam.bai    noTreatment_0hour_NR3C1.bam.bai\n"
     ]
    }
   ],
   "source": [
    "#cd to the folder where you have the aligned, sorted and indexed bam files\n",
    "cd /coursedata/project/ChIP-seq-data/ChIP-seq-bam\n",
    "ls #you see the files\n",
    "#Use bash-variables ChIP_cond1 and ChIP_cond2 to specify the sorted bamfiles in 0hour(cond1) and 1hour(cond2)\n",
    "#macs2 predictd will output an .R script, you need to give it a name (rfile_cond1 and rfile_cond2)\n",
    "\n",
    "ChIP_cond1=\"noTreatment_0hour_NR3C1.bam\"  #FILL!  \n",
    "rfile_cond1=${ChIP_cond1/%'.bam'}'.R'\n",
    "ChIP_cond2=\"dexamethasone_1hour_NR3C1.bam\"\n",
    "rfile_cond2=${ChIP_cond2/%'.bam'}'.R'\n",
    "\n",
    "#specify the output directory, the results from macs2 analysis will be saved in this folder\n",
    "#create the directory first, e.g. using mkdir\n",
    "outdir=//coursedata/users/leey17/part_2  #for example: /coursedata/users/<username>/<macs2_results_folder>\n",
    "mkdir -p $outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run macs2 predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Tue, 14 Dec 2021 10:56:39: # read alignment files... \n",
      "INFO  @ Tue, 14 Dec 2021 10:56:39: # read treatment tags... \n",
      "INFO  @ Tue, 14 Dec 2021 10:56:39: Detected format is: BAM \n",
      "INFO  @ Tue, 14 Dec 2021 10:56:39: * Input file is gzipped. \n",
      "INFO  @ Tue, 14 Dec 2021 10:56:41:  1000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:56:44:  2000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:56:46:  3000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:56:49:  4000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:56:51:  5000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:56:54:  6000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:56:56:  7000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:56:59:  8000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:02:  9000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:04:  10000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:07:  11000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:09:  12000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:12:  13000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:14:  14000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:17:  15000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:19:  16000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:22:  17000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:24:  18000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:27:  19000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:29:  20000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:32:  21000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:35:  22000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:37:  23000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:40:  24000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:42:  25000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:45: 25798398 reads have been read. \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:45: tag size is determined as 51 bps \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:45: # tag size = 51 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:45: # total tags in alignment file: 25798398 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:45: # Build Peak Model... \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:45: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:49: #2 number of paired peaks: 3678 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:49: start model_add_line... \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:49: start X-correlation... \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:49: end of X-cor \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:49: # finished! \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:49: # predicted fragment length is 50 bps \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:49: # alternative fragment length(s) may be 50,169,188,220,277,388,408,493,526 bps \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:49: # Generate R script for model : //coursedata/users/leey17/part_2/noTreatment_0hour_NR3C1.R \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:50: # read alignment files... \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:50: # read treatment tags... \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:50: Detected format is: BAM \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:50: * Input file is gzipped. \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:52:  1000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:55:  2000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:57:57:  3000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:00:  4000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:02:  5000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:05:  6000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:08:  7000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:10:  8000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:13:  9000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:15:  10000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:18:  11000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:21:  12000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:23:  13000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:26:  14000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:28:  15000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:31:  16000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:34:  17000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:36:  18000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:39: 18853266 reads have been read. \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:39: tag size is determined as 51 bps \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:39: # tag size = 51 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:39: # total tags in alignment file: 18853266 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:39: # Build Peak Model... \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:39: #2 looking for paired plus/minus strand peaks... \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:43: #2 number of paired peaks: 13483 \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:43: start model_add_line... \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:43: start X-correlation... \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:43: end of X-cor \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:43: # finished! \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:43: # predicted fragment length is 226 bps \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:43: # alternative fragment length(s) may be 226 bps \n",
      "INFO  @ Tue, 14 Dec 2021 10:58:43: # Generate R script for model : //coursedata/users/leey17/part_2/dexamethasone_1hour_NR3C1.R \n"
     ]
    }
   ],
   "source": [
    "macs2 predictd -i $ChIP_cond1 -g hs --bw 300 --mfold 5 50 --rfile $rfile_cond1 --outdir $outdir \n",
    "macs2 predictd -i $ChIP_cond2 -g hs --bw 300 --mfold 5 50 --rfile $rfile_cond2 --outdir $outdir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null device \n",
      "          1 \n"
     ]
    }
   ],
   "source": [
    "cd //coursedata/users/leey17/part_2 && Rscript dexamethasone_1hour_NR3C1.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null device \n",
      "          1 \n"
     ]
    }
   ],
   "source": [
    "cd //coursedata/users/leey17/part_2 && Rscript noTreatment_0hour_NR3C1.R "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot cross-correlation figures\n",
    "The output of ```macs2 predictd ``` is an ```.R``` script that draws the figures which you use to estimate the fragment length d. Run the ```.R``` scripts using ```source()``` to plot the figures as a pdf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:** Why it is important to estimate the protein-bound DNA fragment lengths? How MACS performs the estimation? What are the `--bw` and `--mfold` options control the estimation. In your report, include the figures obtained from the fragment length estimation and comment them. What is the estimated fragment lengths for NR3C1 ChIP-seq data? How did you come to your conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Remove duplicate reads from both ChIP and Control reads (0.25 points)\n",
    "Filter duplicate reads using ```macs2 filterdup```, you can do this after estimating the fragment length as in this pipeline, or you can do this before Step 1, you can choose. Filter duplicates out from both ChIP and Control sample. You need to add ```-f BAM``` option for ```macs2 filterdup``` to recognize the format as BAM. Note that the output of ```macs2 filterdup``` is in ```bed``` format. First, for the ChIP reads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Fri, 10 Dec 2021 15:37:00: read tag files... \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:00: # read treatment tags... \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:03:  1000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:06:  2000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:08:  3000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:10:  4000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:12:  5000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:14:  6000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:17:  7000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:20:  8000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:22:  9000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:24:  10000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:26:  11000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:28:  12000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:30:  13000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:33:  14000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:35:  15000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:38:  16000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:40:  17000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:42:  18000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:44:  19000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:47:  20000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:49:  21000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:51:  22000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:53:  23000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:55:  24000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:37:58:  25000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:01: 25798398 reads have been read. \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:01: tag size = 51 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:01:  total tags in alignment file: 25798398 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:01: calculate max duplicate tags in single position based on binomal distribution... \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:01:  max_dup_tags based on binomal = 2 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:01: filter out redundant tags at the same location and the same strand by allowing at most 2 tag(s) \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:01:  tags after filtering in alignment file: 25574399 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:01:  Redundant rate of alignment file: 0.01 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:01: Write to BED file \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:23: finished! Check noTreatment_0hour_NR3C1.bed. \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:24: read tag files... \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:24: # read treatment tags... \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:27:  1000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:29:  2000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:32:  3000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:35:  4000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:37:  5000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:40:  6000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:42:  7000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:44:  8000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:46:  9000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:48:  10000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:51:  11000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:53:  12000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:56:  13000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:38:58:  14000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:00:  15000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:03:  16000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:05:  17000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:08:  18000000 \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:11: 18853266 reads have been read. \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:11: tag size = 51 \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:11:  total tags in alignment file: 18853266 \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:11: calculate max duplicate tags in single position based on binomal distribution... \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:11:  max_dup_tags based on binomal = 2 \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:11: filter out redundant tags at the same location and the same strand by allowing at most 2 tag(s) \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:11:  tags after filtering in alignment file: 18784295 \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:11:  Redundant rate of alignment file: 0.00 \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:11: Write to BED file \n",
      "INFO  @ Fri, 10 Dec 2021 15:39:29: finished! Check dexamethasone_1hour_NR3C1.bed. \n"
     ]
    }
   ],
   "source": [
    "macs2 filterdup -f BAM -i $ChIP_cond1 -g hs -o ${ChIP_cond1/%'.bam'}'.bed' --outdir $outdir\n",
    "macs2 filterdup -f BAM -i $ChIP_cond2 -g hs -o ${ChIP_cond2/%'.bam'}'.bed' --outdir $outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for the Control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Control_cond1=\"noTreatment_0hour_Control.bam\"\n",
    "Control_cond2=\"dexamethasone_1hour_Control.bam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Tue, 14 Dec 2021 10:59:08: read tag files... \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:08: # read treatment tags... \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:10:  1000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:13:  2000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:16:  3000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:18:  4000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:21:  5000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:24:  6000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:26:  7000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:29:  8000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:32:  9000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:34:  10000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:37:  11000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:40:  12000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:42:  13000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:45:  14000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:48:  15000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:50:  16000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:53:  17000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:56:  18000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:59:58:  19000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:01:  20000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:04:  21000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:07:  22000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:10:  23000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:13:  24000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:16:  25000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:19:  26000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:22:  27000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:25:  28000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:28:  29000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:31:  30000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:34:  31000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:36:  32000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:39:  33000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:42:  34000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:44:  35000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:47:  36000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:50:  37000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:52:  38000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:55:  39000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:00:58:  40000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:00:  41000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:03:  42000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:06:  43000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:08:  44000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:11:  45000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:14:  46000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:17:  47000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:19:  48000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:22:  49000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:25: 49819154 reads have been read. \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:26: tag size = 51 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:26:  total tags in alignment file: 49819154 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:26: calculate max duplicate tags in single position based on binomal distribution... \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:26:  max_dup_tags based on binomal = 2 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:26: filter out redundant tags at the same location and the same strand by allowing at most 2 tag(s) \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:26:  tags after filtering in alignment file: 48877397 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:26:  Redundant rate of alignment file: 0.02 \n",
      "INFO  @ Tue, 14 Dec 2021 11:01:26: Write to BED file \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:09: finished! Check noTreatment_0hour_Control.bed. \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:10: read tag files... \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:10: # read treatment tags... \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:13:  1000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:15:  2000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:18:  3000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:21:  4000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:23:  5000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:26:  6000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:29:  7000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:31:  8000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:34:  9000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:37:  10000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:39:  11000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:41:  12000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:43:  13000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:46:  14000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:48:  15000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:50:  16000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:53:  17000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:56:  18000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:02:58:  19000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:00:  20000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:02:  21000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:05:  22000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:07:  23000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:09:  24000000 \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:11: 24388542 reads have been read. \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:11: tag size = 51 \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:11:  total tags in alignment file: 24388542 \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:11: calculate max duplicate tags in single position based on binomal distribution... \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:11:  max_dup_tags based on binomal = 2 \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:11: filter out redundant tags at the same location and the same strand by allowing at most 2 tag(s) \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:11:  tags after filtering in alignment file: 24325846 \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:11:  Redundant rate of alignment file: 0.00 \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:11: Write to BED file \n",
      "INFO  @ Tue, 14 Dec 2021 11:03:33: finished! Check dexamethasone_1hour_Control.bed. \n"
     ]
    }
   ],
   "source": [
    "macs2 filterdup -f BAM -i $Control_cond1 -g hs -o ${Control_cond1/%'.bam'}'.bed' --outdir $outdir\n",
    "macs2 filterdup -f BAM -i $Control_cond2 -g hs -o ${Control_cond2/%'.bam'}'.bed' --outdir $outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Questions:** Why it is important to remove duplicate reads and MACS performs the filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extend ChIP reads to get the ChIP coverage track (0.25 points)\n",
    "\n",
    "In other words, generate a pileup track in ```bedGraph```format for the ChIP samples using the ```bed``` files obtained in Step 2. Use ```macs2 pileup```. Extend reads in 5' to 3' direction (the default behavior of the ```pileup``` subcommand). \n",
    "\n",
    "Note: In the earlier macs version, shifting was performed, but in macs2 the only option is to extend the reads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $outdir #go to the folder where you generated the .bed files\n",
    "extsize=226 #Fill the fragment length you obtained in Step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Tue, 14 Dec 2021 10:48:54: # Existing file b'//coursedata/users/leey17/part_2/noTreatment_0hour_NR3C1.bdg' will be replaced! \n",
      "INFO  @ Tue, 14 Dec 2021 10:48:54: # read alignment files... \n",
      "INFO  @ Tue, 14 Dec 2021 10:48:54: # read treatment tags... \n",
      "INFO  @ Tue, 14 Dec 2021 10:48:55:  1000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:48:56:  2000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:48:57:  3000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:48:58:  4000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:48:59:  5000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:00:  6000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:01:  7000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:01:  8000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:02:  9000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:03:  10000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:04:  11000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:05:  12000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:06:  13000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:06:  14000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:07:  15000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:08:  16000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:09:  17000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:10:  18000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:10:  19000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:11:  20000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:12:  21000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:13:  22000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:14:  23000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:15:  24000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:16:  25000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:17: tag size is determined as 51 bps \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:17: # tag size = 51 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:17: # total tags in alignment file: 25574401 \n",
      "INFO  @ Tue, 14 Dec 2021 10:49:17: # Pileup alignment file, extend each read towards downstream direction with 226 bps \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:07: # Done! Check noTreatment_0hour_NR3C1.bdg \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:07: # Existing file b'//coursedata/users/leey17/part_2/dexamethasone_1hour_NR3C1.bdg' will be replaced! \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:07: # read alignment files... \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:07: # read treatment tags... \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:08:  1000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:09:  2000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:11:  3000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:12:  4000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:13:  5000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:14:  6000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:15:  7000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:16:  8000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:17:  9000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:19:  10000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:20:  11000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:21:  12000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:22:  13000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:23:  14000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:25:  15000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:26:  16000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:27:  17000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:28:  18000000 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:29: tag size is determined as 51 bps \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:29: # tag size = 51 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:29: # total tags in alignment file: 18784306 \n",
      "INFO  @ Tue, 14 Dec 2021 10:50:29: # Pileup alignment file, extend each read towards downstream direction with 226 bps \n",
      "INFO  @ Tue, 14 Dec 2021 10:51:07: # Done! Check dexamethasone_1hour_NR3C1.bdg \n"
     ]
    }
   ],
   "source": [
    "\n",
    "macs2 pileup -f BED -i ${ChIP_cond1/%'.bam'}'.bed' -o ${ChIP_cond1/%'.bam'}'.bdg'  --extsize=$extsize --outdir $outdir\n",
    "macs2 pileup -f BED -i ${ChIP_cond2/%'.bam'}'.bed' -o ${ChIP_cond2/%'.bam'}'.bdg'  --extsize=$extsize --outdir $outdir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build local bias tracks from Control data (0.5 points)\n",
    "\n",
    "We compute the local bias by computing the local biases surrounding a genomic loci. The surrounding local bias is computed using genomic window of varying sizes, and the maximum bias from the different windows is chosen as the final local bias.\n",
    " \n",
    "We compute the 1kb window bias, 10kb bias, the size of fragment length bias (d estimated as Step 1), and the bias from the whole genomic background.\n",
    "\n",
    "### The d-background\n",
    "\n",
    "It is assumed that the cutting site of a aligned read in the control sample contains the noise representing a region surrounding the genomic loci.\n",
    "\n",
    "Extend the cutting site (5' end of the read) of the control reads to both sides using ```macs2 pileup``` with ```-B``` option.  To do this, take half of your estimated fragment length d (d/2) rounded to the nearest integer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Wed, 15 Dec 2021 17:19:20: # Existing file b'//coursedata/users/leey17/part_2/noTreatment_0hour_Control_d_bg.bdg' will be replaced! \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:20: # read alignment files... \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:20: # read treatment tags... \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:21:  1000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:22:  2000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:23:  3000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:24:  4000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:25:  5000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:27:  6000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:28:  7000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:29:  8000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:30:  9000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:31:  10000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:32:  11000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:33:  12000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:34:  13000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:35:  14000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:37:  15000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:38:  16000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:39:  17000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:40:  18000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:41:  19000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:42:  20000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:43:  21000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:44:  22000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:46:  23000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:46:  24000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:47:  25000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:48:  26000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:49:  27000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:50:  28000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:52:  29000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:53:  30000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:54:  31000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:55:  32000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:56:  33000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:57:  34000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:58:  35000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:19:59:  36000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:01:  37000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:02:  38000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:03:  39000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:04:  40000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:05:  41000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:06:  42000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:08:  43000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:09:  44000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:10:  45000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:11:  46000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:12:  47000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:14:  48000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:15: tag size is determined as 51 bps \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:15: # tag size = 51 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:15: # total tags in alignment file: 48877397 \n",
      "INFO  @ Wed, 15 Dec 2021 17:20:15: # Pileup alignment file, extend each read towards up/downstream direction with 113 bps \n",
      "INFO  @ Wed, 15 Dec 2021 17:21:55: # Done! Check noTreatment_0hour_Control_d_bg.bdg \n",
      "INFO  @ Wed, 15 Dec 2021 17:21:55: # Existing file b'//coursedata/users/leey17/part_2/dexamethasone_1hour_Control_d_bg.bdg' will be replaced! \n",
      "INFO  @ Wed, 15 Dec 2021 17:21:55: # read alignment files... \n",
      "INFO  @ Wed, 15 Dec 2021 17:21:55: # read treatment tags... \n",
      "INFO  @ Wed, 15 Dec 2021 17:21:56:  1000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:21:58:  2000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:21:59:  3000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:00:  4000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:01:  5000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:03:  6000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:04:  7000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:05:  8000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:06:  9000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:08:  10000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:09:  11000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:10:  12000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:11:  13000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:12:  14000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:14:  15000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:15:  16000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:16:  17000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:18:  18000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:19:  19000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:20:  20000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:21:  21000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:22:  22000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:24:  23000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:25:  24000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:26: tag size is determined as 51 bps \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:26: # tag size = 51 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:26: # total tags in alignment file: 24325853 \n",
      "INFO  @ Wed, 15 Dec 2021 17:22:26: # Pileup alignment file, extend each read towards up/downstream direction with 113 bps \n",
      "INFO  @ Wed, 15 Dec 2021 17:23:17: # Done! Check dexamethasone_1hour_Control_d_bg.bdg \n"
     ]
    }
   ],
   "source": [
    "extsize_half=113 #Fill half of the fragment length you obtained in Step 1.\n",
    "macs2 pileup -f BED -i ${Control_cond1/%'.bam'}'.bed' -B --extsize $extsize_half -o ${Control_cond1/%'.bam'}'_d_bg.bdg' --outdir $outdir\n",
    "macs2 pileup -f BED -i ${Control_cond2/%'.bam'}'.bed' -B --extsize $extsize_half -o ${Control_cond2/%'.bam'}'_d_bg.bdg' --outdir $outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The slocal background. \n",
    "As slocal window we use a 1kb local window. Imagine that each cutting site (5' end of the sequenced read) represents a 1kb surrounding noise, extend the cutting sites by 500 to both sides (1kb=2 x 500bp). **Fill in the XXX part.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Wed, 15 Dec 2021 17:23:51: # read alignment files... \n",
      "INFO  @ Wed, 15 Dec 2021 17:23:51: # read treatment tags... \n",
      "INFO  @ Wed, 15 Dec 2021 17:23:52:  1000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:23:53:  2000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:23:55:  3000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:23:56:  4000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:23:57:  5000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:23:58:  6000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:23:59:  7000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:00:  8000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:02:  9000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:03:  10000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:04:  11000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:05:  12000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:06:  13000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:08:  14000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:09:  15000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:10:  16000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:11:  17000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:12:  18000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:13:  19000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:15:  20000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:16:  21000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:17:  22000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:18:  23000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:19:  24000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:20:  25000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:21:  26000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:23:  27000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:24:  28000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:25:  29000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:26:  30000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:27:  31000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:28:  32000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:29:  33000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:31:  34000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:32:  35000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:33:  36000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:34:  37000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:35:  38000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:36:  39000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:37:  40000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:39:  41000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:40:  42000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:41:  43000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:42:  44000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:43:  45000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:44:  46000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:46:  47000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:47:  48000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:49: tag size is determined as 51 bps \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:49: # tag size = 51 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:49: # total tags in alignment file: 48877397 \n",
      "INFO  @ Wed, 15 Dec 2021 17:24:49: # Pileup alignment file, extend each read towards up/downstream direction with 500 bps \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:41: # Done! Check noTreatment_0hour_Control_1k_bg.bdg \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:41: # read alignment files... \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:41: # read treatment tags... \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:42:  1000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:43:  2000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:45:  3000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:46:  4000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:47:  5000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:48:  6000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:50:  7000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:51:  8000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:52:  9000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:53:  10000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:55:  11000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:56:  12000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:57:  13000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:26:58:  14000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:00:  15000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:01:  16000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:02:  17000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:03:  18000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:05:  19000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:06:  20000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:07:  21000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:08:  22000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:10:  23000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:11:  24000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:12: tag size is determined as 51 bps \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:12: # tag size = 51 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:12: # total tags in alignment file: 24325853 \n",
      "INFO  @ Wed, 15 Dec 2021 17:27:12: # Pileup alignment file, extend each read towards up/downstream direction with 500 bps \n",
      "INFO  @ Wed, 15 Dec 2021 17:28:06: # Done! Check dexamethasone_1hour_Control_1k_bg.bdg \n"
     ]
    }
   ],
   "source": [
    "macs2 pileup -f BED -i ${Control_cond1/%'.bam'}'.bed' -B --extsize 500 -o ${Control_cond1/%'.bam'}'_1k_bg.bdg' --outdir $outdir\n",
    "macs2 pileup -f BED -i ${Control_cond2/%'.bam'}'.bed' -B --extsize 500 -o ${Control_cond2/%'.bam'}'_1k_bg.bdg' --outdir $outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization of the slocal background\n",
    "The file ``` ${Control_cond1/%'.bam'}'_1k_bg.bdg' ``` contains the slocal background from control at condition 1. Because the ChIP signal track was built by extending reads into d size fragments, \n",
    "we have to normalize the 1kb noise by multiplying the values by d/slocal, which is d/1000. \n",
    " Note, we don't have to do this for d background because the multiplier is simply 1. **Note: Remove unnormalized local background files when you do not need them anymore to save storage space! Use ```rm filename ``` (see examples).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalization is done using ```macs2 bdgopt```.  Compute the normalization constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Wed, 15 Dec 2021 17:28:49: Read and build bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:31:19: Modify bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:31:38: Write bedGraph of modified scores... \n",
      "INFO  @ Wed, 15 Dec 2021 17:33:22: Finished 'multiply'! Please check '//coursedata/users/leey17/part_2/noTreatment_0hour_Control_1k_bg_norm.bdg'! \n",
      "INFO  @ Wed, 15 Dec 2021 17:33:22: Read and build bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:34:45: Modify bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:34:55: Write bedGraph of modified scores... \n",
      "INFO  @ Wed, 15 Dec 2021 17:35:48: Finished 'multiply'! Please check '//coursedata/users/leey17/part_2/dexamethasone_1hour_Control_1k_bg_norm.bdg'! \n"
     ]
    }
   ],
   "source": [
    "normalization_constant_slocal=0.226 # Fill!\n",
    "\n",
    "macs2 bdgopt -i ${Control_cond1/%'.bam'}'_1k_bg.bdg' -m multiply -p $normalization_constant_slocal -o ${Control_cond1/%'.bam'}'_1k_bg_norm.bdg' --outdir $outdir\n",
    "macs2 bdgopt -i ${Control_cond2/%'.bam'}'_1k_bg.bdg' -m multiply -p $normalization_constant_slocal -o ${Control_cond2/%'.bam'}'_1k_bg_norm.bdg' --outdir $outdir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnormalized version\n",
    "rm ${Control_cond1/%'.bam'}'_1k_bg.bdg'\n",
    "rm ${Control_cond2/%'.bam'}'_1k_bg.bdg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The llocal background\n",
    "As llocal window we use a 10kb local window. Normalize similarly as the slocal background. **Fill in the XXX part.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Wed, 15 Dec 2021 16:57:52: # read alignment files... \n",
      "INFO  @ Wed, 15 Dec 2021 16:57:52: # read treatment tags... \n",
      "INFO  @ Wed, 15 Dec 2021 16:57:53:  1000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:57:54:  2000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:57:55:  3000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:57:57:  4000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:57:58:  5000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:57:59:  6000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:00:  7000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:01:  8000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:03:  9000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:04:  10000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:05:  11000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:06:  12000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:07:  13000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:09:  14000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:10:  15000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:11:  16000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:12:  17000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:13:  18000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:15:  19000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:16:  20000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:17:  21000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:18:  22000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:19:  23000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:21:  24000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:22:  25000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:23:  26000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:24:  27000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:25:  28000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:27:  29000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:28:  30000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:29:  31000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:30:  32000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:32:  33000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:33:  34000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:34:  35000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:35:  36000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:36:  37000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:37:  38000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:39:  39000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:40:  40000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:41:  41000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:42:  42000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:43:  43000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:45:  44000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:46:  45000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:47:  46000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:48:  47000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:49:  48000000 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:51: tag size is determined as 51 bps \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:51: # tag size = 51 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:51: # total tags in alignment file: 48877397 \n",
      "INFO  @ Wed, 15 Dec 2021 16:58:51: # Pileup alignment file, extend each read towards up/downstream direction with 5000 bps \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:10: # Done! Check noTreatment_0hour_Control_10k_bg.bdg \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:10: # read alignment files... \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:10: # read treatment tags... \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:12:  1000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:13:  2000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:14:  3000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:15:  4000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:17:  5000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:18:  6000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:19:  7000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:21:  8000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:22:  9000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:23:  10000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:25:  11000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:26:  12000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:27:  13000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:28:  14000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:30:  15000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:31:  16000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:32:  17000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:33:  18000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:35:  19000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:36:  20000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:37:  21000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:39:  22000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:40:  23000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:41:  24000000 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:42: tag size is determined as 51 bps \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:42: # tag size = 51 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:42: # total tags in alignment file: 24325853 \n",
      "INFO  @ Wed, 15 Dec 2021 17:01:42: # Pileup alignment file, extend each read towards up/downstream direction with 5000 bps \n",
      "INFO  @ Wed, 15 Dec 2021 17:02:47: # Done! Check dexamethasone_1hour_Control_10k_bg.bdg \n"
     ]
    }
   ],
   "source": [
    "macs2 pileup -f BED -i ${Control_cond1/%'.bam'}'.bed' -B --extsize 5000 -o ${Control_cond1/%'.bam'}'_10k_bg.bdg' --outdir $outdir\n",
    "macs2 pileup -f BED -i ${Control_cond2/%'.bam'}'.bed' -B --extsize 5000 -o ${Control_cond2/%'.bam'}'_10k_bg.bdg' --outdir $outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization of the llocal background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Wed, 15 Dec 2021 17:03:48: Read and build bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:07:04: Modify bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:07:22: Write bedGraph of modified scores... \n",
      "INFO  @ Wed, 15 Dec 2021 17:09:23: Finished 'multiply'! Please check '//coursedata/users/leey17/part_2/noTreatment_0hour_Control_10k_bg_norm.bdg'! \n",
      "INFO  @ Wed, 15 Dec 2021 17:09:24: Read and build bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:10:57: Modify bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:11:06: Write bedGraph of modified scores... \n",
      "INFO  @ Wed, 15 Dec 2021 17:12:07: Finished 'multiply'! Please check '//coursedata/users/leey17/part_2/dexamethasone_1hour_Control_10k_bg_norm.bdg'! \n"
     ]
    }
   ],
   "source": [
    "normalization_constant_llocal=0.0226 #Fill\n",
    "macs2 bdgopt -i ${Control_cond1/%'.bam'}'_10k_bg.bdg' -m multiply -p $normalization_constant_llocal -o ${Control_cond1/%'.bam'}'_10k_bg_norm.bdg' --outdir $outdir\n",
    "macs2 bdgopt -i ${Control_cond2/%'.bam'}'_10k_bg.bdg' -m multiply -p $normalization_constant_llocal -o ${Control_cond2/%'.bam'}'_10k_bg_norm.bdg' --outdir $outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnormalized version\n",
    "rm ${Control_cond1/%'.bam'}'_10k_bg.bdg'\n",
    "rm ${Control_cond2/%'.bam'}'_10k_bg.bdg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The whole genome background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole genome background can be calculated as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\textrm{whole genome background}=\\frac{\\textrm{number of control reads} * \\textrm{fragment length (d)} }{ \\textrm{genome size}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The human genome size defined by ```macs``` is 2700000000. Compute the whole genome background values for Control samples at both conditions (0hour and 1 hour). You get the number of control reads for the Control samples, for example, from the output of ```macs2 filterdup```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Control_cond1_whole_genome_bg=4.0912  #Fill!\n",
    "Control_cond2_whole_genome_bg=2.04  #Fill!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the final local background\n",
    "\n",
    "Compute the maximun of slocal, llocal, d background and the whole genome background.\n",
    "\n",
    "First, take the maximum between slocal (1k) and llocal (10k) background, use ```macs2 bdgcmp```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Wed, 15 Dec 2021 17:36:31: Read and build treatment bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:39:26: Read and build control bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:42:24: Build scoreTrackII... \n",
      "INFO  @ Wed, 15 Dec 2021 17:44:40: Calculate scores comparing treatment and control by 'max'... \n",
      "INFO  @ Wed, 15 Dec 2021 17:45:39: Write bedGraph of scores... \n",
      "INFO  @ Wed, 15 Dec 2021 17:48:59: Finished 'max'! Please check 'noTreatment_0hour_Control_1k_10k_bg_norm.bdg'! \n",
      "INFO  @ Wed, 15 Dec 2021 17:49:00: Read and build treatment bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:50:36: Read and build control bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 17:52:12: Build scoreTrackII... \n",
      "INFO  @ Wed, 15 Dec 2021 17:53:18: Calculate scores comparing treatment and control by 'max'... \n",
      "INFO  @ Wed, 15 Dec 2021 17:53:50: Write bedGraph of scores... \n",
      "INFO  @ Wed, 15 Dec 2021 17:55:44: Finished 'max'! Please check 'dexamethasone_1hour_Control_1k_10k_bg_norm.bdg'! \n"
     ]
    }
   ],
   "source": [
    "macs2 bdgcmp -m max -t ${Control_cond1/%'.bam'}'_10k_bg_norm.bdg' -c ${Control_cond1/%'.bam'}'_1k_bg_norm.bdg' -o ${Control_cond1/%'.bam'}'_1k_10k_bg_norm.bdg'\n",
    "\n",
    "\n",
    "macs2 bdgcmp -m max -t ${Control_cond2/%'.bam'}'_10k_bg_norm.bdg' -c ${Control_cond2/%'.bam'}'_1k_bg_norm.bdg' -o ${Control_cond2/%'.bam'}'_1k_10k_bg_norm.bdg'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, take the maximum by comparing with d background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm ${Control_cond1/%'.bam'}'_10k_bg_norm.bdg'\n",
    "rm ${Control_cond1/%'.bam'}'_1k_bg_norm.bdg'\n",
    "rm ${Control_cond2/%'.bam'}'_10k_bg_norm.bdg'\n",
    "rm ${Control_cond2/%'.bam'}'_1k_bg_norm.bdg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Wed, 15 Dec 2021 18:27:11: Read and build treatment bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 18:30:23: Read and build control bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 18:33:18: Build scoreTrackII... \n",
      "INFO  @ Wed, 15 Dec 2021 18:35:41: Calculate scores comparing treatment and control by 'max'... \n",
      "INFO  @ Wed, 15 Dec 2021 18:36:41: Write bedGraph of scores... \n",
      "INFO  @ Wed, 15 Dec 2021 18:40:49: Finished 'max'! Please check '//coursedata/users/leey17/part_2/noTreatment_0hour_Control_d_1k_10_kbg.bdg'! \n",
      "INFO  @ Wed, 15 Dec 2021 18:40:52: Read and build treatment bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 18:42:28: Read and build control bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 18:43:49: Build scoreTrackII... \n",
      "INFO  @ Wed, 15 Dec 2021 18:45:07: Calculate scores comparing treatment and control by 'max'... \n",
      "INFO  @ Wed, 15 Dec 2021 18:45:39: Write bedGraph of scores... \n",
      "INFO  @ Wed, 15 Dec 2021 18:47:57: Finished 'max'! Please check '//coursedata/users/leey17/part_2/dexamethasone_1hour_Control_d_1k_10_kbg.bdg'! \n"
     ]
    }
   ],
   "source": [
    "macs2 bdgcmp -m max -t ${Control_cond1/%'.bam'}'_1k_10k_bg_norm.bdg' -c ${Control_cond1/%'.bam'}'_d_bg.bdg' -o ${Control_cond1/%'.bam'}'_d_1k_10_kbg.bdg' --outdir $outdir\n",
    "\n",
    "macs2 bdgcmp -m max -t ${Control_cond2/%'.bam'}'_1k_10k_bg_norm.bdg' -c ${Control_cond2/%'.bam'}'_d_bg.bdg' -o  ${Control_cond2/%'.bam'}'_d_1k_10_kbg.bdg' --outdir $outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, combine with the genome wide background. The file ```${Control_cond1/%'.bam'}'_local_bias_raw.bdg' ``` is a bedGraph file containing the raw local bias from control data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm ${Control_cond1/%'.bam'}'_1k_10k_bg_norm.bdg'\n",
    "rm ${Control_cond1/%'.bam'}'_d_bg.bdg'\n",
    "rm ${Control_cond2/%'.bam'}'_1k_10k_bg_norm.bdg'\n",
    "rm ${Control_cond2/%'.bam'}'_d_bg.bdg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Wed, 15 Dec 2021 18:59:48: Read and build bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 19:03:31: Modify bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 19:03:52: Write bedGraph of modified scores... \n",
      "INFO  @ Wed, 15 Dec 2021 19:06:16: Finished 'max'! Please check '//coursedata/users/leey17/part_2/noTreatment_0hour_Control_local_bias_raw.bdg'! \n",
      "INFO  @ Wed, 15 Dec 2021 19:06:19: Read and build bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 19:08:35: Modify bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 19:08:47: Write bedGraph of modified scores... \n",
      "INFO  @ Wed, 15 Dec 2021 19:10:06: Finished 'max'! Please check '//coursedata/users/leey17/part_2/dexamethasone_1hour_Control_local_bias_raw.bdg'! \n"
     ]
    }
   ],
   "source": [
    "\n",
    "macs2 bdgopt -i ${Control_cond1/%'.bam'}'_d_1k_10_kbg.bdg' -m max -p $Control_cond1_whole_genome_bg -o ${Control_cond1/%'.bam'}'_local_bias_raw.bdg' --outdir $outdir\n",
    "macs2 bdgopt -i ${Control_cond2/%'.bam'}'_d_1k_10_kbg.bdg' -m max -p $Control_cond2_whole_genome_bg -o ${Control_cond2/%'.bam'}'_local_bias_raw.bdg' --outdir $outdir\n",
    "\n",
    "#rm ${Control_cond1/%'.bam'}'_d_1k_10_kbg.bdg'\n",
    "#rm ${Control_cond2/%'.bam'}'_d_1k_10_kbg.bdg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:** How the several sources of local and global variability and biases in ChIP-seq data are taken into account in the statistical model of MACS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm ${Control_cond1/%'.bam'}'_d_1k_10_kbg.bdg'\n",
    "rm ${Control_cond2/%'.bam'}'_d_1k_10_kbg.bdg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Call peaks at both time points (1 point)\n",
    "The differential binding analysis performs a three-way comparison to find out which genomic regions have differential enrichment of the TF ChIP-seq reads between the two conditions (0hour and 1 hour). A basic requirement is that the regions should be at least enriched in either condition (the region is called as a peak in either condition). So first we need to identify the peaks in both conditions.\n",
    "\n",
    "### The local Poisson test\n",
    "Perform the local Poisson test, i.e. test the ChIP-seq at each basepair againts the corresponding local lambda derived from Control with the Poisson model. Use ```macs2 bdgcmp ```. The output is the the -log10 q-values for each basepair along the genome. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Sat, 18 Dec 2021 17:36:45: Read and build treatment bedGraph... \n",
      "INFO  @ Sat, 18 Dec 2021 17:38:09: Read and build control bedGraph... \n",
      "INFO  @ Sat, 18 Dec 2021 17:41:33: Build scoreTrackII... \n",
      "INFO  @ Sat, 18 Dec 2021 17:42:53: Calculate scores comparing treatment and control by 'qpois'... \n",
      "INFO  @ Sat, 18 Dec 2021 17:50:43: Write bedGraph of scores... \n",
      "INFO  @ Sat, 18 Dec 2021 17:51:16: Finished 'qpois'! Please check '//coursedata/users/leey17/part_2/noTreatment_0hour_NR3C1_qvalue.bdg'! \n",
      "INFO  @ Sat, 18 Dec 2021 17:51:17: Read and build treatment bedGraph... \n",
      "INFO  @ Sat, 18 Dec 2021 17:52:25: Read and build control bedGraph... \n",
      "INFO  @ Sat, 18 Dec 2021 17:54:21: Build scoreTrackII... \n",
      "INFO  @ Sat, 18 Dec 2021 17:55:12: Calculate scores comparing treatment and control by 'qpois'... \n",
      "INFO  @ Sat, 18 Dec 2021 18:01:06: Write bedGraph of scores... \n",
      "INFO  @ Sat, 18 Dec 2021 18:01:33: Finished 'qpois'! Please check '//coursedata/users/leey17/part_2/dexamethasone_1hour_NR3C1_qvalue.bdg'! \n"
     ]
    }
   ],
   "source": [
    "cd $outdir\n",
    "macs2 bdgcmp -t ${ChIP_cond1/%'.bam'}'.bdg' -c ${Control_cond1/%'.bam'}'_local_bias_raw.bdg' -m qpois -o ${ChIP_cond1/%'.bam'}'_qvalue.bdg' --outdir $outdir\n",
    "macs2 bdgcmp -t ${ChIP_cond2/%'.bam'}'.bdg' -c ${Control_cond2/%'.bam'}'_local_bias_raw.bdg' -m qpois -o ${ChIP_cond2/%'.bam'}'_qvalue.bdg' --outdir $outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:** What motivates the Poisson distribution assumption to statistically model the number of aligned reads in a given genomic loci? What are the null and alternative hypotheses in the statistical test that MACS performs? How the p-value is computed? How the FDR is controlled?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak calling\n",
    "Use ```macs2 bdgpeakcall``` to call the peaks. Set the minimum length of peak the same as the fragment length d, and set the maximum gap between significant points in a peak as the tag/read size (see the macs2 output of the previous steps).  Set the q-value threshold as 0.05 using option ```-c```. Remember the scores in the output from ```bdgcmp``` are in -log10 form so if you the q-value threshold is 0.05, then the -log10 value is about 1.3.\n",
    "\n",
    "If two nearby regions are both above the q-value threshold but the region in-between is lower, and if the region in-between is small enough, we should merge the two nearby regions together into a bigger one and tolerate the fluctuation. The default value is 30, but the recommended value is set as the tag/read length since the read length represent the resolution of the dataset. Use option -g to set the tag size.\n",
    "\n",
    "We don't want to call too many small 'peaks' so we need to have a minimum length for the peak (option ```-l```). Use the fragment size d as the parameter of the minimum length of peak.\n",
    "\n",
    "The output of ```macs2 bdgpeakcall``` is a narrowPeak format file (a type of BED file) which contains locations of peaks and the peak summit location in the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO  @ Sat, 18 Dec 2021 18:02:50: Read and build bedGraph... \n",
      "INFO  @ Sat, 18 Dec 2021 18:02:50: Call peaks from bedGraph... \n",
      "INFO  @ Sat, 18 Dec 2021 18:02:50: Write peaks... \n",
      "INFO  @ Sat, 18 Dec 2021 18:02:50: Done \n",
      "INFO  @ Sat, 18 Dec 2021 18:02:50: Read and build bedGraph... \n",
      "INFO  @ Sat, 18 Dec 2021 18:02:52: Call peaks from bedGraph... \n",
      "INFO  @ Sat, 18 Dec 2021 18:02:52: Write peaks... \n",
      "INFO  @ Sat, 18 Dec 2021 18:02:52: Done \n"
     ]
    }
   ],
   "source": [
    "#Fill XXX\n",
    "macs2 bdgpeakcall -i ${ChIP_cond1/%'.bam'}'_qvalue.bdg' -c 1.3 -l $extsize -g 51 -o ${ChIP_cond1/%'.bam'}'_peaks.bed' --outdir $outdir\n",
    "\n",
    "macs2 bdgpeakcall -i ${ChIP_cond2/%'.bam'}'_qvalue.bdg' -c 1.3 -l $extsize -g 51 -o ${ChIP_cond2/%'.bam'}'_peaks.bed' --outdir $outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:** When there are multiple adjacent basepairs with q-value smaller than the threshold, how macs defines the peaks? What macs reports for each peak?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Extract the effective sequencing depths for both time points (0.5 points)\n",
    "\n",
    "From the earlier macs2 outputs, extract the number of tags/reads in ChIP sample and in Control samples at both time points. From these numbers you need to extract the effective sequencing depth at 0 hour condition and at 1 hour condition. The effective sequencing depth of a condition is the smaller number of tags of ChIP and Control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill XXX !\n",
    "tagnro_ChIP_0hour=25574399 \n",
    "tagnro_ChIP_Control_0hour=48877397\n",
    "tagnro_ChIP_1hour=18784295  \n",
    "tagnro_ChIP_Control_1hour=24325846\n",
    "\n",
    "eff_seq_depth_0hour=25574399\n",
    "eff_seq_depth_1hour=18784295"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:** When calling the differential binding sites, why it is important to equalize the number of sequencing reads for different conditions/time points and how it is performed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Call the differential binding sites (0.5 points)\n",
    "\n",
    "Use ``` macs2 bdgdiff```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NR3C1\n",
      "INFO  @ Wed, 15 Dec 2021 19:10:36: Read and build treatment 1 bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 19:12:01: Read and build control 1 bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 19:15:20: Read and build treatment 2 bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 19:16:26: Read and build control 2 bedGraph... \n",
      "INFO  @ Wed, 15 Dec 2021 19:26:11: Write peaks... \n",
      "INFO  @ Wed, 15 Dec 2021 19:26:11: Done \n"
     ]
    }
   ],
   "source": [
    "#Extract the TF name from the filename\n",
    "TF=${ChIP_cond1/%'.bam'}\n",
    "TF=${TF/#'noTreatment_0hour_'}\n",
    "echo $TF\n",
    "macs2 bdgdiff --t1 ${ChIP_cond1/%'.bam'}'.bdg' --c1 ${Control_cond1/%'.bam'}'_local_bias_raw.bdg' --t2 ${ChIP_cond2/%'.bam'}'.bdg' --c2 ${Control_cond2/%'.bam'}'_local_bias_raw.bdg' --d1 $eff_seq_depth_0hour --d2 $eff_seq_depth_1hour --o-prefix $TF'_0hour_vs_1hour' --outdir $outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give you three files:\n",
    "\n",
    "* ```<TF>_0hour_vs_1hour_cond1.bed``` unique reagions in condition 1 (0hour), i.e. peaks having more enrichment in condition 1 over condition 2\n",
    "* ```<TF>_0hour_vs_1hour_cond2.bed``` unique regions in condition  (1hour), i.e. peaks having more enrichment in condition 2 over condition 1\n",
    "* ```<TF>_0hour_vs_1hour_common.bed``` common regions in both conditions , i.e. peaks having similar enrichment in both conditions  \n",
    "\n",
    "How many differentially bound regions you found for NR3C1? What is the number of peaks \n",
    "* having more enrichment at 0hour over 1hour,\n",
    "* having more enrichment at 1hour over 0hour, and  \n",
    "* having similar enrichment in both conditions?\n",
    "\n",
    "The number of peaks can be obtained, for example, by counting the rows of the resulting ```.bed ``` files.\n",
    "\n",
    "## Next, you can continue with Part 3 using the peaks having more enrichment at 1hour over 0hour condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3852 /coursedata/users/leey17/part_2/NR3C1_0hour_vs_1hour_c3.0_cond2.bed\n"
     ]
    }
   ],
   "source": [
    "wc -l /coursedata/users/leey17/part_2/NR3C1_0hour_vs_1hour_c3.0_cond2.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 /coursedata/users/leey17/part_2/NR3C1_0hour_vs_1hour_c3.0_cond1.bed\n"
     ]
    }
   ],
   "source": [
    "wc -l /coursedata/users/leey17/part_2/NR3C1_0hour_vs_1hour_c3.0_cond1.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 /coursedata/users/leey17/part_2/NR3C1_0hour_vs_1hour_c3.0_common.bed\n"
     ]
    }
   ],
   "source": [
    "wc -l /coursedata/users/leey17/part_2/NR3C1_0hour_vs_1hour_c3.0_common.bed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
